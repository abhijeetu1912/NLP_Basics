{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHC_UQTuCAY4"
      },
      "source": [
        "## Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPjBqTbcD7tQ",
        "outputId": "9b2ef7c8-7ddf-4d52-b044-28c0c2ef2c10"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zEalYYOZnlS"
      },
      "source": [
        "## Loading Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKgr5QzxD-PA",
        "outputId": "ec34c419-8377-4adf-ae00-e3909cac5078"
      },
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score \n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOI7X2YgCAY_"
      },
      "source": [
        "## Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "DHq5UX6iD-MA",
        "outputId": "da25f52c-948c-49a8-fee0-744ea31c4e87"
      },
      "source": [
        "# using the SQLite Table to read data.\n",
        "con = sqlite3.connect(F'/content/drive/MyDrive/Aazon_Review_Data/database.sqlite') \n",
        "\n",
        "#filtering only positive and negative reviews i.e. ignoring neutral reviews with Score = 3\n",
        "data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3\"\"\", con)\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(525814, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                               Text\n",
              "0   1  ...  I have bought several of the Vitality canned d...\n",
              "1   2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2   3  ...  This is a confection that has been around a fe...\n",
              "3   4  ...  If you are looking for the secret ingredient i...\n",
              "4   5  ...  Great taffy at a great price.  There was a wid...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH919nXX-x5x",
        "outputId": "56c5b2dd-20b3-4c1b-8af1-2040e4995598"
      },
      "source": [
        "#sampling 100k reviews\n",
        "df = data.sample(n = 100000, random_state = 1).reset_index(drop = True)\n",
        "df.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EvpYkyXD-Gd",
        "outputId": "c810ec17-d2fd-423b-a549-5ffc45ed6e2e"
      },
      "source": [
        "#proprtion of review scores\n",
        "df.Score.value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    69027\n",
              "4    15328\n",
              "1     9963\n",
              "2     5682\n",
              "Name: Score, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "i5FbgqMFD-EJ",
        "outputId": "4749545f-d6be-478e-9000-ec87aa0f4e1b"
      },
      "source": [
        "# Give reviews with Score > 3 a positive rating, and reviews with a score < 3 a negative rating.\n",
        "df['Score'] = np.where(df['Score'] > 3, 0, 1)\n",
        "df.head(3)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>87501</td>\n",
              "      <td>B001D0GV6I</td>\n",
              "      <td>AXL5GJLYKKLMX</td>\n",
              "      <td>KCBrad \"KCBrad\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1272672000</td>\n",
              "      <td>Great flavor</td>\n",
              "      <td>This is one of my favorite flavors.  This Fren...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>476117</td>\n",
              "      <td>B001EQ4EHE</td>\n",
              "      <td>A261ERFPYHP556</td>\n",
              "      <td>Vinsanity18 \"Vince\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1274054400</td>\n",
              "      <td>Tastes Great</td>\n",
              "      <td>I bought this for my girl friend that recently...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>225032</td>\n",
              "      <td>B001LNTY70</td>\n",
              "      <td>A2GH0L50430WJF</td>\n",
              "      <td>E. Reynolds</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1336262400</td>\n",
              "      <td>Mostly lime!</td>\n",
              "      <td>Not a big fan of chili actually... so these al...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Id  ...                                               Text\n",
              "0   87501  ...  This is one of my favorite flavors.  This Fren...\n",
              "1  476117  ...  I bought this for my girl friend that recently...\n",
              "2  225032  ...  Not a big fan of chili actually... so these al...\n",
              "\n",
              "[3 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX5b3dc5CAZS"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecj9mkDJD9-n"
      },
      "source": [
        "#Sorting data according to ProductId in ascending order\n",
        "df.sort_values('ProductId', axis = 0, ascending = True, inplace = True, kind = 'quicksort', na_position = 'last')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHn521FSD9yq",
        "outputId": "3343284d-85b3-406a-c5c6-a087519bda71"
      },
      "source": [
        "#Deduplication of entries\n",
        "df.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep ='first', inplace = True)\n",
        "df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86856, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO5nLKeFCAZf"
      },
      "source": [
        "<b>Insight:-</b> In some rows, value of HelpfulnessNumerator can be greater than HelpfulnessDenominator which is not practically possible hence these two rows too are removed from calcualtions.\n",
        "It is not possible that more number of people found these reviews useful compared to number of people who have seen this review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdtjeWdiETM0",
        "outputId": "0f6adb12-adc5-4835-e250-15da802bd443"
      },
      "source": [
        "#removing records with HelpfulnessNumerator > HelpfulnessDenominator\n",
        "df = df[df.HelpfulnessNumerator <= df.HelpfulnessDenominator]\n",
        "df.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86855, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "-Mba4eD1ETJz",
        "outputId": "63f0230f-1e0b-4a7a-8abc-c32cbd2f005d"
      },
      "source": [
        "#selecting required columns\n",
        "df = df[['Text', 'Score']]\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>77580</th>\n",
              "      <td>The same author wrote \"Where the Wild Things A...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73066</th>\n",
              "      <td>This book contains a collection of twelve shor...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72413</th>\n",
              "      <td>This copy is smaller than I expected (mostly b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70563</th>\n",
              "      <td>I can remember seeing the show when it aired o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94893</th>\n",
              "      <td>Great book, perfect condition arrived in a sho...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    Text  Score\n",
              "77580  The same author wrote \"Where the Wild Things A...      0\n",
              "73066  This book contains a collection of twelve shor...      0\n",
              "72413  This copy is smaller than I expected (mostly b...      0\n",
              "70563  I can remember seeing the show when it aired o...      0\n",
              "94893  Great book, perfect condition arrived in a sho...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM0Cy_iIETGA",
        "outputId": "07726a6d-6aeb-4d56-eb31-d0927a566ec1"
      },
      "source": [
        "#Distribution of +ve and -ve Reviews\n",
        "print(\"Proportion of -ve Reviews :\", round(df['Score'].mean(), 2), \"\\n\")\n",
        "df['Score'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Proportion of -ve Reviews : 0.16 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    73233\n",
              "1    13622\n",
              "Name: Score, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxBsuBylCAZr"
      },
      "source": [
        "## Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-XnedncQHZk"
      },
      "source": [
        "#stopwords \n",
        "stop_words = stopwords.words('english') \n",
        "negative = [\"no\", \"nor\", \"not\", 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn',\n",
        "          \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'mightn',\n",
        "          \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\",\n",
        "          'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'don', \"don't\"]\n",
        "stop_words = [x for x in stop_words if x not in negative]\n",
        "\n",
        "#stemming\n",
        "stemmer = PorterStemmer()  \n",
        "\n",
        "#function to replace negative words by not to reduce the dimension of data\n",
        "def replace_by_not(x):\n",
        "    if x in negative:\n",
        "       x = 'not'\n",
        "    return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1alA753Ja0EA"
      },
      "source": [
        "For word2vec, stemming and lemmatization is not advised, so we will be not using in our text pre-processing function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v-MJZltETD6"
      },
      "source": [
        "#text pre-processing function\n",
        "def preprocess(text):\n",
        "    text = text.lower()                                                         #to lower case\n",
        "    text = re.sub('http[s]?://\\S+', ' ', text)                                  #removing urls\n",
        "    text = re.sub('<[^<]+?>', ' ', text)                                        #removing html tags\n",
        "    text = re.sub('\\S*\\d\\S*', ' ', text)                                        #removing alphanumeric words\n",
        "    text = re.sub('[^A-Za-z]+', ' ', text)                                      #removing special characters\n",
        "    text = re.sub(r'\\b[a-zA-Z]\\b', ' ', text)                                   #removing single character (length) words\n",
        "    text = re.sub('\\s{2,}', ' ', text)                                          #removing multiple white spaces\n",
        "    text = text.strip()                                                         #removing spaces from start & end of the text\n",
        "    text_tokenized = word_tokenize(text)                                        #tokenization\n",
        "    \n",
        "    tokens = []\n",
        "    for token in text_tokenized:                              \n",
        "        if token not in stop_words:                                             #removing stopwords  \n",
        "            token = replace_by_not(token)                                       #replacing negative words by \"NOT\" to reduce the dimension of data                                             #replacing negative words by \"NOT\" to reduce the dimension of data       \n",
        "            token = stemmer.stem(token)                                         #stemming\n",
        "            tokens.append(token)                                                #returns text back in sentence form\n",
        "    return tokens                                                               #returns tokenized text in list"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "GJEwpJdQETAT",
        "outputId": "b6556f54-b0fe-42e4-8cec-d31e4a5cc39f"
      },
      "source": [
        "#applying text pre-processing function\n",
        "df['Text'] = df['Text'].apply(lambda x: preprocess(x))\n",
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>77580</th>\n",
              "      <td>[author, wrote, wild, thing, carol, king, wrot...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73066</th>\n",
              "      <td>[book, contain, collect, twelv, short, stateme...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72413</th>\n",
              "      <td>[copi, smaller, expect, mostli, not, pay, atte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70563</th>\n",
              "      <td>[rememb, see, show, air, televis, year, ago, c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94893</th>\n",
              "      <td>[great, book, perfect, condit, arriv, short, a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    Text  Score\n",
              "77580  [author, wrote, wild, thing, carol, king, wrot...      0\n",
              "73066  [book, contain, collect, twelv, short, stateme...      0\n",
              "72413  [copi, smaller, expect, mostli, not, pay, atte...      0\n",
              "70563  [rememb, see, show, air, televis, year, ago, c...      0\n",
              "94893  [great, book, perfect, condit, arriv, short, a...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhEWhR0qES93"
      },
      "source": [
        "#Extracting X & y for Training\n",
        "X = df['Text']\n",
        "y = df['Score']\n",
        "\n",
        "del df"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUImHJ9JJxrN"
      },
      "source": [
        "## Featurization - Bag of Words, TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS9AC3zXJzsx"
      },
      "source": [
        "### Bag of Word: Uni-gram & Bi-gram Combined (Count)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kwmmCJpJ8y8",
        "outputId": "32aa2308-99c1-4538-aec6-6d63da6b50b9"
      },
      "source": [
        "#Bag of words : Uni-gram & Bi-gram\n",
        "count_vect = CountVectorizer(ngram_range = (1, 2), token_pattern = None, tokenizer = lambda doc: doc, preprocessor = lambda doc: doc, min_df = 20, max_features = 2500) \n",
        "count_vect.fit(X)\n",
        "\n",
        "X_uni_bi = count_vect.transform(X)\n",
        "print(\"Some Feature Names \", count_vect.get_feature_names()[:20])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some Feature Names  ['abl', 'abl find', 'abl get', 'absolut', 'absolut delici', 'absolut love', 'absorb', 'accept', 'accord', 'acid', 'across', 'act', 'activ', 'actual', 'actual tast', 'ad', 'ad sugar', 'add', 'add littl', 'add water']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy6XPE6uK6Qb"
      },
      "source": [
        "### TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_xBkQJKK9rr",
        "outputId": "0933e324-510e-451e-b742-87c97071a54e"
      },
      "source": [
        "#tf-idf\n",
        "tf_idf_vect = TfidfVectorizer(ngram_range = (1, 2), token_pattern = None, tokenizer = lambda doc: doc, preprocessor = lambda doc: doc, min_df = 20, max_features = 2500)\n",
        "tf_idf_vect.fit(X)\n",
        "\n",
        "X_tf_idf = tf_idf_vect.transform(X)\n",
        "print(\"Some Feature Names \", tf_idf_vect.get_feature_names()[0:10])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some Feature Names  ['abl', 'abl find', 'abl get', 'absolut', 'absolut delici', 'absolut love', 'absorb', 'accept', 'accord', 'acid']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPRqyrEmZ_zT"
      },
      "source": [
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo0YIC50gBpy"
      },
      "source": [
        "### Building Word2Vec Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfspgVaYES64"
      },
      "source": [
        "#word2vec model using gensim library\n",
        "word2vec = Word2Vec(X, min_count = 10, window = 10, size = 200, workers = 3)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f93CMZSnMpJ"
      },
      "source": [
        "### Vocabulary of Word2Vec Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWlR1u9wnRK2"
      },
      "source": [
        "#vobabulary of word2vec model\n",
        "vocabulary = word2vec.wv.vocab"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XdbAf9AESwK"
      },
      "source": [
        "### Average of Word2Vec Vectors for Document Vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYp9hl2qEStR"
      },
      "source": [
        "#avg word2vec function\n",
        "def avg_word2vec(x): \n",
        "    vectors = np.zeros((200, ), dtype = \"float32\")\n",
        "    words = 0\n",
        "    for item in x:\n",
        "        if item in vocabulary:                                    #checking if word is present in word2vec vocabulary \n",
        "           words += 1                                                           \n",
        "           vectors = np.add(vectors, word2vec.wv[item])           #vector representation of the word\n",
        "    avg = np.divide(vectors, words)                               #average of all available vectors\n",
        "    return avg if words > 0 else np.zeros((200, ), dtype = \"float32\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPn7U6oBmLxE",
        "outputId": "614d2da9-5aa1-481d-f7c3-6f10fb0b3d5a"
      },
      "source": [
        "#calculating avg word2vec\n",
        "df_size = len(X)\n",
        "ndim = 200\n",
        "X_word2vec = np.zeros((df_size, ndim),  dtype = \"float32\")\n",
        "for i, x in enumerate(X):\n",
        "    X_word2vec[i] = avg_word2vec(x)\n",
        "X_word2vec.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86855, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvMytx7EUTjZ"
      },
      "source": [
        "### Creating Train & Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB-GTntqUSo2"
      },
      "source": [
        "#train & test partioning for ngram data\n",
        "X_train_ngram, X_test_ngram, y_train_ngram, y_test_ngram = train_test_split(X_uni_bi, y, test_size = 0.3, shuffle = True, random_state = 1)\n",
        "del X_uni_bi"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoaOWEd7HlCh"
      },
      "source": [
        "#train & test partioning for tf-idf data\n",
        "X_train_tf_idf, X_test_tf_idf, y_train_tf_idf, y_test_tf_idf = train_test_split(X_tf_idf.toarray(), y, test_size = 0.3, shuffle = True, random_state = 1)\n",
        "del X_tf_idf"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrGlaydYHnWj"
      },
      "source": [
        "#train & test partioning for word2vec data\n",
        "X_train_word2vec, X_test_word2vec, y_train_word2vec, y_test_word2vec = train_test_split(X_word2vec, y, test_size = 0.3, shuffle = True, random_state = 1)\n",
        "del X_word2vec"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSDKgQYRiNse",
        "outputId": "74cc9adc-a125-4ae6-ff0c-c9760f37902e"
      },
      "source": [
        "#shape of training data of ngram, tf-idf and word2vec data respectively\n",
        "print(X_train_ngram.shape, y_train_ngram.shape)\n",
        "print(X_train_tf_idf.shape, y_train_tf_idf.shape)\n",
        "print(X_train_word2vec.shape, y_train_word2vec.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60798, 2500) (60798,)\n",
            "(60798, 2500) (60798,)\n",
            "(60798, 200) (60798,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvgyOp30jXT5",
        "outputId": "33d8538b-5e86-48c9-83b7-1a32886d0142"
      },
      "source": [
        "#checking proportion of -ve reviews in training & data of ngram, tf-idf and word2vec data respectively\n",
        "np.mean(y_train_tf_idf)\n",
        "print(\"Train n-gram: \", round(np.mean(y_train_ngram), 2), \"   Test n-gram\", round(np.mean(y_test_ngram), 2))\n",
        "print(\"Train tf-idf: \", round(np.mean(y_train_tf_idf), 2),  \"   Test tf-idf\", round(np.mean(y_test_tf_idf), 2))\n",
        "print(\"Train word2vec: \", round(np.mean(y_train_word2vec), 2),  \"   Test word2vec\", round(np.mean(y_test_word2vec), 2))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train n-gram:  0.16    Test n-gram 0.16\n",
            "Train tf-idf:  0.16    Test tf-idf 0.16\n",
            "Train word2vec:  0.16    Test word2vec 0.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YyIm9dqrmlX"
      },
      "source": [
        "## Applying Machine Learning Algorithms for Sentiment Analysis\n",
        "1. Naive Bayes\n",
        "2. Logistic Regression\n",
        "3. Decision Tree\n",
        "4. Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McZ0oIUt9wBz"
      },
      "source": [
        "### Function for Performance Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIU5dBIU9xAU"
      },
      "source": [
        "#function to get performance metrics\n",
        "def accuracy_metrics(y, y_pred, y_prob):\n",
        "    results = confusion_matrix(y, y_pred) \n",
        "    print('Confusion Matrix :')\n",
        "    print(results) \n",
        "    print('Accuracy Score :',accuracy_score(y, y_pred))\n",
        "    print('Precision : ', precision_score(y, y_pred))\n",
        "    print('Recall : ', recall_score(y, y_pred))\n",
        "    print('FI Score : ', f1_score(y, y_pred, average='macro'))\n",
        "    print('Area under the Curve : ', roc_auc_score(y, y_prob))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw92FBAYGS2C"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w90Wy5Mr9fyF"
      },
      "source": [
        "### Naive Bayes on Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQdZWkVS9nY9",
        "outputId": "10f7a4d3-a21d-4198-a347-7d47e291e80d"
      },
      "source": [
        "#naive bayes on bag of words\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train_ngram, y_train_ngram)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTtV2EWh-Xv4",
        "outputId": "0196d716-cb8b-4a85-e3c7-c690863d0b31"
      },
      "source": [
        "#accuracy metrics on train data\n",
        "train_prob = nb.predict_proba(X_train_ngram)[:,1]\n",
        "train_pred = nb.predict(X_train_ngram)\n",
        "\n",
        "accuracy_metrics(y_train_ngram, train_pred, train_prob)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[47779  3474]\n",
            " [ 2227  7318]]\n",
            "Accuracy Score : 0.9062304681075035\n",
            "Precision :  0.6780948851000741\n",
            "Recall :  0.7666841278156102\n",
            "FI Score :  0.831686166604258\n",
            "Area under the Curve :  0.9359902600905132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e4fCCmC-fwp",
        "outputId": "9c64331a-21bc-468c-b6c6-fd9cdf48f614"
      },
      "source": [
        "#accuracy metrics on test data\n",
        "test_prob = nb.predict_proba(X_test_ngram)[:,1]\n",
        "test_pred = nb.predict(X_test_ngram)\n",
        "\n",
        "accuracy_metrics(y_test_ngram, test_pred, test_prob)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[20505  1475]\n",
            " [  997  3080]]\n",
            "Accuracy Score : 0.9051310588325594\n",
            "Precision :  0.6761800219538968\n",
            "Recall :  0.755457444199166\n",
            "FI Score :  0.8283863074337239\n",
            "Area under the Curve :  0.9318589234131056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeCeU5XB-8oo"
      },
      "source": [
        "### Naive Bayes on TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J23icZWY-_b0",
        "outputId": "bd9970af-bcda-408d-ba1e-a928b2705e60"
      },
      "source": [
        "#naive bayes on tf-idf\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train_tf_idf, y_train_tf_idf)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrzHfvT7_OPn",
        "outputId": "6d943a82-86ba-4bff-d55a-78316447a581"
      },
      "source": [
        "#accuracy metrics on train data\n",
        "train_prob = nb.predict_proba(X_train_tf_idf)[:,1]\n",
        "train_pred = nb.predict(X_train_tf_idf)\n",
        "\n",
        "accuracy_metrics(y_train_tf_idf, train_pred, train_prob)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[40929 10324]\n",
            " [ 1208  8337]]\n",
            "Accuracy Score : 0.8103227079838152\n",
            "Precision :  0.4467606237607845\n",
            "Recall :  0.8734415924567837\n",
            "FI Score :  0.7338343237179887\n",
            "Area under the Curve :  0.8662790072199789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvy8HJk4_Oir",
        "outputId": "2ef00ace-1ba5-4e74-aab7-01b6c2f6d52c"
      },
      "source": [
        "#accuracy metrics on test data\n",
        "test_prob = nb.predict_proba(X_test_tf_idf)[:,1]\n",
        "test_pred = nb.predict(X_test_tf_idf)\n",
        "\n",
        "accuracy_metrics(y_test_tf_idf, test_pred, test_prob)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[17514  4466]\n",
            " [  654  3423]]\n",
            "Accuracy Score : 0.8035076946693787\n",
            "Precision :  0.4338952972493345\n",
            "Recall :  0.8395879323031641\n",
            "FI Score :  0.7222964318333382\n",
            "Area under the Curve :  0.8482404288421499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohpQ5Tp3_ghb"
      },
      "source": [
        "### Naive Bayes on Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWHUPww__iQe",
        "outputId": "2fb7dc23-00a1-4c0d-f2b5-b2edc390c9b8"
      },
      "source": [
        "#naive bayes on word2vec\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train_word2vec, y_train_word2vec)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzbMz0wo_iHg",
        "outputId": "802bc877-9c11-4212-ea9b-e14d19d02e1f"
      },
      "source": [
        "#accuracy metrics on train data\n",
        "train_prob = nb.predict_proba(X_train_word2vec)[:,1]\n",
        "train_pred = nb.predict(X_train_word2vec)\n",
        "\n",
        "accuracy_metrics(y_train_word2vec, train_pred, train_prob)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[39822 11431]\n",
            " [ 1965  7580]]\n",
            "Accuracy Score : 0.7796638047304187\n",
            "Precision :  0.39871653253379624\n",
            "Recall :  0.7941330539549503\n",
            "FI Score :  0.6934527977007843\n",
            "Area under the Curve :  0.8667273720358287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbPPlYIf_h-5",
        "outputId": "5e415e6e-c691-4d05-c3e3-5a165ff0889f"
      },
      "source": [
        "#accuracy metrics on test data\n",
        "test_prob = nb.predict_proba(X_test_word2vec)[:,1]\n",
        "test_pred = nb.predict(X_test_word2vec)\n",
        "\n",
        "accuracy_metrics(y_test_word2vec, test_pred, test_prob)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[17182  4798]\n",
            " [  801  3276]]\n",
            "Accuracy Score : 0.7851249184480178\n",
            "Precision :  0.40574684171414416\n",
            "Recall :  0.8035320088300221\n",
            "FI Score :  0.6995551413408979\n",
            "Area under the Curve :  0.870759205806871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlmUkjvBCWfH"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGY6Q3RMCma4"
      },
      "source": [
        "### LogIstic Regression on Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRKZLIhkCma5",
        "outputId": "5250231a-e0f3-470e-ff7f-71483fcc20ee"
      },
      "source": [
        "#logistic regression on bag of words\n",
        "lr = LogisticRegression(max_iter = 1000, random_state = 1)\n",
        "lr.fit(X_train_ngram, y_train_ngram)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCXZWU13Cma6",
        "outputId": "ae55bd08-a874-4d67-fc3e-bd227dbbff4f"
      },
      "source": [
        "#accuracy metrics on train data\n",
        "train_prob = lr.predict_proba(X_train_ngram)[:,1]\n",
        "train_pred = lr.predict(X_train_ngram)\n",
        "\n",
        "accuracy_metrics(y_train_ngram, train_pred, train_prob)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[50188  1065]\n",
            " [ 2522  7023]]\n",
            "Accuracy Score : 0.9410013487285765\n",
            "Precision :  0.8683234421364985\n",
            "Recall :  0.7357778941854374\n",
            "FI Score :  0.8810359724174082\n",
            "Area under the Curve :  0.9691562691951737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zS0SCSwCma6",
        "outputId": "6ace433f-d719-4d64-9d9b-764b7e06eb37"
      },
      "source": [
        "#accuracy metrics on test data\n",
        "test_prob = lr.predict_proba(X_test_ngram)[:,1]\n",
        "test_pred = lr.predict(X_test_ngram)\n",
        "\n",
        "accuracy_metrics(y_test_ngram, test_pred, test_prob)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[21306   674]\n",
            " [ 1303  2774]]\n",
            "Accuracy Score : 0.9241278735080785\n",
            "Precision :  0.8045243619489559\n",
            "Recall :  0.6804022565611969\n",
            "FI Score :  0.8464687288977981\n",
            "Area under the Curve :  0.9417165202249778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCGMY-dvCma7"
      },
      "source": [
        "### Logistic Regression on TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFl5dMNpCma7",
        "outputId": "d55e7b45-7665-4352-e9cb-a166aacb649c"
      },
      "source": [
        "#logistic regression on tf-idf\n",
        "lr = LogisticRegression(max_iter = 1000, random_state = 1)\n",
        "lr.fit(X_train_tf_idf, y_train_tf_idf)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dpzgl9J7Cma7",
        "outputId": "514b7cf3-734c-4bb4-8acf-fae579a95e7b"
      },
      "source": [
        "#accuracy metrics on train data\n",
        "train_prob = lr.predict_proba(X_train_tf_idf)[:,1]\n",
        "train_pred = lr.predict(X_train_tf_idf)\n",
        "\n",
        "accuracy_metrics(y_train_tf_idf, train_pred, train_prob)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[50431   822]\n",
            " [ 3268  6277]]\n",
            "Accuracy Score : 0.9327280502648113\n",
            "Precision :  0.8842090435272574\n",
            "Recall :  0.6576217915138816\n",
            "FI Score :  0.8576478027954744\n",
            "Area under the Curve :  0.9662158155287479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcEiypupCma8",
        "outputId": "4d4bc587-4d03-4f69-980a-8768c8a62ac4"
      },
      "source": [
        "#accuracy metrics on test data\n",
        "test_prob = lr.predict_proba(X_test_tf_idf)[:,1]\n",
        "test_pred = lr.predict(X_test_tf_idf)\n",
        "\n",
        "accuracy_metrics(y_test_tf_idf, test_pred, test_prob)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[21544   436]\n",
            " [ 1545  2532]]\n",
            "Accuracy Score : 0.9239743638945389\n",
            "Precision :  0.8530997304582211\n",
            "Recall :  0.6210448859455482\n",
            "FI Score :  0.8374264200932436\n",
            "Area under the Curve :  0.9565904786008553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt4vDZ6KCma8"
      },
      "source": [
        "### Logistic Regression on Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-VBOPT5Cma8",
        "outputId": "cfb103ae-dd48-424e-c143-ec1b5e0e2148"
      },
      "source": [
        "#logistic regression on word2vec\n",
        "lr = LogisticRegression(max_iter = 1000, random_state = 1)\n",
        "lr.fit(X_train_word2vec, y_train_word2vec)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFQESpCBCma8",
        "outputId": "56b114af-2cd0-4792-9c90-fd51626fc1f4"
      },
      "source": [
        "#accuracy metrics on train data\n",
        "train_prob = lr.predict_proba(X_train_word2vec)[:,1]\n",
        "train_pred = lr.predict(X_train_word2vec)\n",
        "\n",
        "accuracy_metrics(y_train_word2vec, train_pred, train_prob)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[49693  1560]\n",
            " [ 3977  5568]]\n",
            "Accuracy Score : 0.9089279252606993\n",
            "Precision :  0.7811447811447811\n",
            "Recall :  0.5833420639078052\n",
            "FI Score :  0.8075670814107918\n",
            "Area under the Curve :  0.9330691876759605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_M2LN3bCma9",
        "outputId": "7edecc46-ce63-46d2-f7c2-f11986f66fe8"
      },
      "source": [
        "#accuracy metrics on test data\n",
        "test_prob = lr.predict_proba(X_test_word2vec)[:,1]\n",
        "test_pred = lr.predict(X_test_word2vec)\n",
        "\n",
        "accuracy_metrics(y_test_word2vec, test_pred, test_prob)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[21267   713]\n",
            " [ 1707  2370]]\n",
            "Accuracy Score : 0.9071266838085735\n",
            "Precision :  0.768731754784301\n",
            "Recall :  0.5813097866077999\n",
            "FI Score :  0.8040891831575567\n",
            "Area under the Curve :  0.9328244197291314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGZJ9ZoSCp0P"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7-62tz6Cp0P"
      },
      "source": [
        "### Decision Tree on Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SkX2GM9Cp0P",
        "outputId": "7c143b4d-3be8-4702-aca9-06a699194a76"
      },
      "source": [
        "#decision tree on bag of words\n",
        "dt = DecisionTreeClassifier(min_samples_leaf = 30, random_state = 1)\n",
        "dt.fit(X_train_ngram, y_train_ngram)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=30, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=1, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKh-f_n0Cp0P",
        "outputId": "8ae8bcc5-4737-4625-e1ef-2315159d7eb1"
      },
      "source": [
        "#accuracy metrics on train data\n",
        "train_prob = dt.predict_proba(X_train_ngram)[:,1]\n",
        "train_pred = dt.predict(X_train_ngram)\n",
        "\n",
        "accuracy_metrics(y_train_ngram, train_pred, train_prob)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[49453  1800]\n",
            " [ 5017  4528]]\n",
            "Accuracy Score : 0.8878746011381954\n",
            "Precision :  0.7155499367888748\n",
            "Recall :  0.4743844944997381\n",
            "FI Score :  0.7530243753109165\n",
            "Area under the Curve :  0.9062161019088973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwWOs4C_Cp0Q",
        "outputId": "7678e32d-4255-4060-a996-8a9e51d54f1e"
      },
      "source": [
        "#accuracy metrics on test data\n",
        "test_prob = dt.predict_proba(X_test_ngram)[:,1]\n",
        "test_pred = dt.predict(X_test_ngram)\n",
        "\n",
        "accuracy_metrics(y_test_ngram, test_pred, test_prob)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[21092   888]\n",
            " [ 2312  1765]]\n",
            "Accuracy Score : 0.8771923091683617\n",
            "Precision :  0.6652845834903882\n",
            "Recall :  0.43291636006867795\n",
            "FI Score :  0.7270038285154072\n",
            "Area under the Curve :  0.8490123694852256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzlYyMcvCp0Q"
      },
      "source": [
        "### Decision Tree on TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwNNsBmECp0Q",
        "outputId": "4eb3afe8-0cb5-4621-822e-f47c4ce41c37"
      },
      "source": [
        "#decision tree on tf-idf\n",
        "dt = DecisionTreeClassifier(min_samples_leaf = 30, random_state = 1)\n",
        "dt.fit(X_train_tf_idf, y_train_tf_idf)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=30, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=1, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g68zbNw-Cp0Q",
        "outputId": "e05bb35d-7b59-4234-c027-75dad74d9310"
      },
      "source": [
        "#accuracy metrics on train data\n",
        "train_prob = dt.predict_proba(X_train_tf_idf)[:,1]\n",
        "train_pred = dt.predict(X_train_tf_idf)\n",
        "\n",
        "accuracy_metrics(y_train_tf_idf, train_pred, train_prob)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[49503  1750]\n",
            " [ 4903  4642]]\n",
            "Accuracy Score : 0.8905720582913912\n",
            "Precision :  0.7262202753441802\n",
            "Recall :  0.4863279203771608\n",
            "FI Score :  0.759788526202852\n",
            "Area under the Curve :  0.9202115723806358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9fhU1p6Cp0Q",
        "outputId": "e51ed9bf-6865-4cb6-8f1a-cf588f6bee8e"
      },
      "source": [
        "#accuracy metrics on test data\n",
        "test_prob = dt.predict_proba(X_test_tf_idf)[:,1]\n",
        "test_pred = dt.predict(X_test_tf_idf)\n",
        "\n",
        "accuracy_metrics(y_test_tf_idf, test_pred, test_prob)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[20999   981]\n",
            " [ 2325  1752]]\n",
            "Accuracy Score : 0.8731243044095637\n",
            "Precision :  0.6410537870472008\n",
            "Recall :  0.4297277409860191\n",
            "FI Score :  0.7207818780382123\n",
            "Area under the Curve :  0.8329765693297563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnJOEtrVCp0R"
      },
      "source": [
        "### Decision Tree on Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPT9EJ0ZCp0R",
        "outputId": "0b10fdc4-1d9f-472c-d4d4-5998cdafdee4"
      },
      "source": [
        "#decision tree on word2vec\n",
        "dt = DecisionTreeClassifier(min_samples_leaf = 50, random_state = 1)\n",
        "dt.fit(X_train_word2vec, y_train_word2vec)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=50, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=1, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G_p9cB4Cp0R",
        "outputId": "84689083-c681-41af-b097-03acfecc8c03"
      },
      "source": [
        "#accuracy metrics on train data\n",
        "train_prob = dt.predict_proba(X_train_word2vec)[:,1]\n",
        "train_pred = dt.predict(X_train_word2vec)\n",
        "\n",
        "accuracy_metrics(y_train_word2vec, train_pred, train_prob)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[49607  1646]\n",
            " [ 4863  4682]]\n",
            "Accuracy Score : 0.8929405572551729\n",
            "Precision :  0.7398862199747156\n",
            "Recall :  0.4905185961236249\n",
            "FI Score :  0.7641830216955781\n",
            "Area under the Curve :  0.9279673672170383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK9odkoPCp0R",
        "outputId": "cba672c0-d95a-4d3a-f552-c3065a89f23e"
      },
      "source": [
        "#accuracy metrics on test data\n",
        "test_prob = dt.predict_proba(X_test_word2vec)[:,1]\n",
        "test_pred = dt.predict(X_test_word2vec)\n",
        "\n",
        "accuracy_metrics(y_test_word2vec, test_pred, test_prob)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[20972  1008]\n",
            " [ 2454  1623]]\n",
            "Accuracy Score : 0.8671374294815213\n",
            "Precision :  0.6168757126567845\n",
            "Recall :  0.3980868285504047\n",
            "FI Score :  0.703827195494878\n",
            "Area under the Curve :  0.8322509726883963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzXOiqybCrks"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnc7o96MCrkt"
      },
      "source": [
        "### Random Forest on Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIRen0QuCrkt",
        "outputId": "50dbbda7-f58d-49ef-bb64-a226080c4bb1"
      },
      "source": [
        "#random forest on bag of words\n",
        "rf = RandomForestClassifier(n_estimators = 200, min_samples_leaf = 20, n_jobs = 3, random_state = 1)\n",
        "rf.fit(X_train_ngram, y_train_ngram)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=20, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=3,\n",
              "                       oob_score=False, random_state=1, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn1YgCDeCrku",
        "outputId": "8f6f1e02-6b2a-4961-9332-437c169916ba"
      },
      "source": [
        "#accuracy metrics on train data\n",
        "train_prob = rf.predict_proba(X_train_ngram)[:,1]\n",
        "train_pred = rf.predict(X_train_ngram)\n",
        "\n",
        "accuracy_metrics(y_train_ngram, train_pred, train_prob)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[51190    63]\n",
            " [ 7861  1684]]\n",
            "Accuracy Score : 0.8696667653541235\n",
            "Precision :  0.9639381797366915\n",
            "Recall :  0.17642744892613935\n",
            "FI Score :  0.6132132139422937\n",
            "Area under the Curve :  0.937857848068626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYiV_iGoCrku",
        "outputId": "e82c8cc7-a15b-44e0-eb60-2fb76fced351"
      },
      "source": [
        "#accuracy metrics on test data\n",
        "test_prob = rf.predict_proba(X_test_ngram)[:,1]\n",
        "test_pred = rf.predict(X_test_ngram)\n",
        "\n",
        "accuracy_metrics(y_test_ngram, test_pred, test_prob)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[21945    35]\n",
            " [ 3424   653]]\n",
            "Accuracy Score : 0.867252561691676\n",
            "Precision :  0.9491279069767442\n",
            "Recall :  0.16016678930586215\n",
            "FI Score :  0.6005142808096615\n",
            "Area under the Curve :  0.9225754655100418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2aFucs-Crku"
      },
      "source": [
        "### Random Forest on TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfT_OyfGCrkv",
        "outputId": "ef5dbacf-2875-49eb-d86d-f39555ab5bea"
      },
      "source": [
        "#random forest on tf-idf\n",
        "rf = RandomForestClassifier(n_estimators = 200, min_samples_leaf = 20, n_jobs = 3, random_state = 1)\n",
        "rf.fit(X_train_tf_idf, y_train_tf_idf)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=20, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=3,\n",
              "                       oob_score=False, random_state=1, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G85TILmqCrkv",
        "outputId": "e0e4f818-8eee-4da6-aa81-bfc5cfda6650"
      },
      "source": [
        "#accuracy metrics on train data\n",
        "train_prob = rf.predict_proba(X_train_tf_idf)[:,1]\n",
        "train_pred = rf.predict(X_train_tf_idf)\n",
        "\n",
        "accuracy_metrics(y_train_tf_idf, train_pred, train_prob)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[51167    86]\n",
            " [ 7227  2318]]\n",
            "Accuracy Score : 0.879716438040725\n",
            "Precision :  0.9642262895174709\n",
            "Recall :  0.2428496595075956\n",
            "FI Score :  0.6606432033489271\n",
            "Area under the Curve :  0.9532842636652772\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E9pEF2fCrkw",
        "outputId": "ba92cb8c-d0f9-4dc9-dbd9-9144e056d35a"
      },
      "source": [
        "#accuracy metrics on test data\n",
        "test_prob = rf.predict_proba(X_test_tf_idf)[:,1]\n",
        "test_pred = rf.predict(X_test_tf_idf)\n",
        "\n",
        "accuracy_metrics(y_test_tf_idf, test_pred, test_prob)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[21923    57]\n",
            " [ 3237   840]]\n",
            "Accuracy Score : 0.8735848332501823\n",
            "Precision :  0.9364548494983278\n",
            "Recall :  0.20603384841795438\n",
            "FI Score :  0.6339396853455533\n",
            "Area under the Curve :  0.9241737253948836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaCyhim7Crkw"
      },
      "source": [
        "### Random Forest on Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4MnEwyXCrkw",
        "outputId": "a4a72a22-f8ee-42f2-d88c-70eda13daed5"
      },
      "source": [
        "#random forest on word2vec\n",
        "rf = RandomForestClassifier(n_estimators = 200, min_samples_leaf = 40, n_jobs = 3, random_state = 1)\n",
        "rf.fit(X_train_word2vec, y_train_word2vec)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=40, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=3,\n",
              "                       oob_score=False, random_state=1, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cruoPH2VCrkx",
        "outputId": "209d8fda-4b64-4383-fa4b-b03b86089495"
      },
      "source": [
        "#accuracy metrics on train data\n",
        "train_prob = rf.predict_proba(X_train_word2vec)[:,1]\n",
        "train_pred = rf.predict(X_train_word2vec)\n",
        "\n",
        "accuracy_metrics(y_train_word2vec, train_pred, train_prob)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[50941   312]\n",
            " [ 6018  3527]]\n",
            "Accuracy Score : 0.8958847330504293\n",
            "Precision :  0.9187288356342798\n",
            "Recall :  0.36951283394447354\n",
            "FI Score :  0.7342754677459087\n",
            "Area under the Curve :  0.9580670002201612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMcaNJZFCrkx",
        "outputId": "406900c2-31fe-4e5e-d7f4-3cdd5bd89eb5"
      },
      "source": [
        "#accuracy metrics on test data\n",
        "test_prob = rf.predict_proba(X_test_word2vec)[:,1]\n",
        "test_pred = rf.predict(X_test_word2vec)\n",
        "\n",
        "accuracy_metrics(y_test_word2vec, test_pred, test_prob)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[21750   230]\n",
            " [ 2882  1195]]\n",
            "Accuracy Score : 0.8805695206662317\n",
            "Precision :  0.8385964912280702\n",
            "Recall :  0.29310767721363745\n",
            "FI Score :  0.6838117860015048\n",
            "Area under the Curve :  0.9145330348034189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSdG7ghGX0HY"
      },
      "source": [
        "Logistic regression is giving best performance wrt all metrics. Both precision & recall are comparatively high and balanced compared to other methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApaDLtIKYl9N"
      },
      "source": [
        "## Applying SMOTE Algorithm for Handling Class Imbalance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6qUO80CYrfL"
      },
      "source": [
        "SMOTE on Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVYOWnbAYK1M",
        "outputId": "f5b23015-db99-44b8-ec42-eed3a63339c6"
      },
      "source": [
        "#ngram data - smote algorithm for handling data imbalance\n",
        "print(\"Before OverSampling, Proportion of Label '1': {}\".format(np.mean(y_train_ngram)))\n",
        "\n",
        "sm = SMOTE(k_neighbors = 20, random_state = 1)\n",
        "X_train_ngram_smote, y_train_ngram_smote = sm.fit_sample(X_train_ngram, y_train_ngram)\n",
        "\n",
        "print(\"After OverSampling, Proportion of Label '1': {}\".format(np.mean(y_train_ngram_smote)))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before OverSampling, Proportion of Label '1': 0.15699529589789138\n",
            "After OverSampling, Proportion of Label '1': 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5CIcCeAZCui"
      },
      "source": [
        "SMOTE on TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE6O5SyuZCuk",
        "outputId": "c4ecd4eb-bd3d-433b-9220-5df9ec6a3848"
      },
      "source": [
        "#ngram data - smote algorithm for handling data imbalance\n",
        "print(\"Before OverSampling, Proportion of Label '1': {}\".format(np.mean(y_train_tf_idf)))\n",
        "\n",
        "sm = SMOTE(k_neighbors = 20, random_state = 1)\n",
        "X_train_tf_idf_smote, y_train_tf_idf_smote = sm.fit_sample(X_train_tf_idf, y_train_tf_idf)\n",
        "\n",
        "print(\"After OverSampling, Proportion of Label '1': {}\".format(np.mean(y_train_tf_idf_smote)))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before OverSampling, Proportion of Label '1': 0.15699529589789138\n",
            "After OverSampling, Proportion of Label '1': 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V9ghpowZC_6"
      },
      "source": [
        "SMOTE on Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BflKMWyEZC_6",
        "outputId": "c9c22ab9-8566-4004-9c3e-a0b536e8aa4e"
      },
      "source": [
        "#ngram data - smote algorithm for handling data imbalance\n",
        "print(\"Before OverSampling, Proportion of Label '1': {}\".format(np.mean(y_train_word2vec)))\n",
        "\n",
        "\n",
        "sm = SMOTE(k_neighbors = 20, random_state = 1)\n",
        "X_train_word2vec_smote, y_train_word2vec_smote = sm.fit_sample(X_train_word2vec, y_train_word2vec)\n",
        "\n",
        "print(\"After OverSampling, Proportion of Label '1': {}\".format(np.mean(y_train_word2vec_smote)))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before OverSampling, Proportion of Label '1': 0.15699529589789138\n",
            "After OverSampling, Proportion of Label '1': 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds902H7qjs7y"
      },
      "source": [
        "### Logistic Regression on SMOTE Oversampled Bag of Words Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uzmia0-jbCr",
        "outputId": "dda1f6df-299c-4789-c63f-3d2c1ddf048b"
      },
      "source": [
        "#logistic regression on bag of words (smote)\n",
        "lr = LogisticRegression(max_iter = 1000, random_state = 1)\n",
        "lr.fit(X_train_ngram_smote, y_train_ngram_smote)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2fSXANhjbC_",
        "outputId": "5e33ee16-8469-4be9-9ad4-1bbcf84f13fe"
      },
      "source": [
        "#accuracy metrics on train data\n",
        "train_prob = lr.predict_proba(X_train_ngram)[:,1]\n",
        "train_pred = lr.predict(X_train_ngram)\n",
        "\n",
        "accuracy_metrics(y_train_ngram, train_pred, train_prob)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[47968  3285]\n",
            " [ 1769  7776]]\n",
            "Accuracy Score : 0.9168722655350505\n",
            "Precision :  0.7030105777054516\n",
            "Recall :  0.8146673651126244\n",
            "FI Score :  0.8523435363482039\n",
            "Area under the Curve :  0.9514724421400438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDQHTRs1jbDA",
        "outputId": "48670b98-9314-4b67-8239-5a25147787d4"
      },
      "source": [
        "#accuracy metrics on test data\n",
        "test_prob = lr.predict_proba(X_test_ngram)[:,1]\n",
        "test_pred = lr.predict(X_test_ngram)\n",
        "\n",
        "accuracy_metrics(y_test_ngram, test_pred, test_prob)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[20318  1662]\n",
            " [  942  3135]]\n",
            "Accuracy Score : 0.9000652415857543\n",
            "Precision :  0.6535334584115072\n",
            "Recall :  0.7689477557027226\n",
            "FI Score :  0.823168234405951\n",
            "Area under the Curve :  0.9181385490365961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFa7iPqmkBzx"
      },
      "source": [
        "### Logistic Regression on SMOTE Oversampled TF-IDF Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxXbJqjekB0H",
        "outputId": "77fd409e-04b3-43bb-aa15-fcdaf3bda2f4"
      },
      "source": [
        "#logistic regression on tf-idf (smote)\n",
        "lr = LogisticRegression(max_iter = 1000, random_state = 1)\n",
        "lr.fit(X_train_tf_idf_smote, y_train_tf_idf_smote)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3Xh__MekB0K",
        "outputId": "1036d350-ba50-44ce-c788-9842c7cfa007"
      },
      "source": [
        "#accuracy metrics on train data\n",
        "train_prob = lr.predict_proba(X_train_tf_idf)[:,1]\n",
        "train_pred = lr.predict(X_train_tf_idf)\n",
        "\n",
        "accuracy_metrics(y_train_tf_idf, train_pred, train_prob)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[47056  4197]\n",
            " [  975  8570]]\n",
            "Accuracy Score : 0.9149314122175072\n",
            "Precision :  0.6712618469491658\n",
            "Recall :  0.8978522786799371\n",
            "FI Score :  0.8580517502087988\n",
            "Area under the Curve :  0.9688861029453647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxXoaBKUkB0L",
        "outputId": "dbbc9538-699c-4ece-b6dd-230c7d8411da"
      },
      "source": [
        "#accuracy metrics on test data\n",
        "test_prob = lr.predict_proba(X_test_tf_idf)[:,1]\n",
        "test_pred = lr.predict(X_test_tf_idf)\n",
        "\n",
        "accuracy_metrics(y_test_tf_idf, test_pred, test_prob)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[20066  1914]\n",
            " [  580  3497]]\n",
            "Accuracy Score : 0.9042867559580918\n",
            "Precision :  0.6462761042321198\n",
            "Recall :  0.857738533235222\n",
            "FI Score :  0.8393163806634101\n",
            "Area under the Curve :  0.9564549059360719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm2WaMsqkCJ7"
      },
      "source": [
        "### Logistic Regression on SMOTE Oversampled Word2Vec Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7827LG55kCJ8",
        "outputId": "4dbc54f7-ea07-49e8-d469-47978aa5e8e9"
      },
      "source": [
        "#logistic regression on word2vec (smote)\n",
        "lr = LogisticRegression(max_iter = 1000, random_state = 1)\n",
        "lr.fit(X_train_word2vec_smote, y_train_word2vec_smote)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eNXj0g_kCJ8",
        "outputId": "eac177b3-522b-45a9-953f-d72760ef4232"
      },
      "source": [
        "#accuracy metrics on train data\n",
        "train_prob = lr.predict_proba(X_train_word2vec)[:,1]\n",
        "train_pred = lr.predict(X_train_word2vec)\n",
        "\n",
        "accuracy_metrics(y_train_word2vec, train_pred, train_prob)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[44304  6949]\n",
            " [ 1408  8137]]\n",
            "Accuracy Score : 0.8625448205533077\n",
            "Precision :  0.5393742542754872\n",
            "Recall :  0.852488213724463\n",
            "FI Score :  0.787263186816549\n",
            "Area under the Curve :  0.9331626935543218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9gJgvWdkCJ9",
        "outputId": "a615f941-972f-40bd-e4c6-b2138957cff9"
      },
      "source": [
        "#accuracy metrics on test data\n",
        "test_prob = lr.predict_proba(X_test_word2vec)[:,1]\n",
        "test_pred = lr.predict(X_test_word2vec)\n",
        "\n",
        "accuracy_metrics(y_test_word2vec, test_pred, test_prob)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[18982  2998]\n",
            " [  588  3489]]\n",
            "Accuracy Score : 0.8623786314617953\n",
            "Precision :  0.5378449206104516\n",
            "Recall :  0.8557763061074319\n",
            "FI Score :  0.7871197960878874\n",
            "Area under the Curve :  0.9326510956177299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVV1kVgRjk8O"
      },
      "source": [
        "We can see that applying smote algorithm has boosted the performance of logistic regression model by a good margin. Specially the our focus metric recall has increased significantly.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOHPD2igl80R"
      },
      "source": [
        "Overall logistic regression model trained on oversampled tf-idf data performs the best."
      ]
    }
  ]
}